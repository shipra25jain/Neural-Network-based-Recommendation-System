{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112002c30>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from time import time\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "# import pandas as pd\n",
    "np.random.seed(7)\n",
    "import math\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "# set the device as gpu or cpu depending upon the machine its running on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "weight_decay = 0.00001\n",
    "num_negatives_pretrain = 4\n",
    "num_negatives_pasttest = 100\n",
    "learning_rate = 0.001\n",
    "dropout = 0.2\n",
    "optimizer = 'adam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie lens dataset has some positive interactions between user and movie means movie has been watched by user but doesnt\n",
    "# necessarily imply that user liked the movie. Below class, generates a sparse matrix with value 1 for positive interactions\n",
    "# and 0 otherwise. Initialzing the class with default parameters would return training data with 4 negative interaction for\n",
    "# for every positive interaction and test data with 100 negative interactions for every positive interaction\n",
    "class MovieLensDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, file_name, num_negatives_train=5, num_negatives_test=100):\n",
    "        self.train_matrix = self.load_matrix(file_name + \".train.rating\")\n",
    "        self.n_users, self.n_items = self.train_matrix.shape\n",
    "        self.user_input, self.item_input, self.ratings = self.get_train_instances(self.train_matrix, num_negatives_train)\n",
    "        self.testRatings = self.load_list(file_name + \".test.rating\")\n",
    "        self.testNegatives = self.create_negatives(num_samples=num_negatives_test)\n",
    "        assert len(self.testRatings) == len(self.testNegatives)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'user_id': self.user_input[index],\n",
    "                'item_id': self.item_input[index],\n",
    "                'rating': self.ratings[index]}\n",
    "    def load_matrix(self, filename):\n",
    "        num_users, num_items = 0, 0\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                u, i = int(arr[0]), int(arr[1])\n",
    "                num_users = max(num_users, u)\n",
    "                num_items = max(num_items, i)\n",
    "                line = f.readline()\n",
    "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "                if (rating > 0):\n",
    "                    mat[user, item] = 1.0\n",
    "                line = f.readline()\n",
    "        return mat\n",
    "\n",
    "    def get_train_instances(self, train, num_negatives):\n",
    "        user_input, item_input, ratings = [], [], []\n",
    "        num_users, num_items = train.shape\n",
    "        for (u, i) in train.keys():\n",
    "            user_input.append(u)\n",
    "            item_input.append(i)\n",
    "            ratings.append(1)\n",
    "            for t in range(num_negatives):\n",
    "                j = np.random.randint(1, num_items)\n",
    "                while (u, j) in train:\n",
    "                    j = np.random.randint(1, num_items)\n",
    "                user_input.append(u)\n",
    "                item_input.append(j)\n",
    "                ratings.append(0)\n",
    "        return user_input, item_input, ratings\n",
    "\n",
    "    def load_list(self, filename):\n",
    "        ratingList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item = int(arr[0]), int(arr[1])\n",
    "                ratingList.append([user, item])\n",
    "                line = f.readline()\n",
    "        return ratingList\n",
    "\n",
    "    def create_negatives(self, num_samples=100):\n",
    "        negativeList = []\n",
    "        for user_item_pair in self.testRatings:\n",
    "            user = user_item_pair[0]\n",
    "            item = user_item_pair[1]\n",
    "            negatives = []\n",
    "            for t in range(num_samples):\n",
    "                j = np.random.randint(1, self.n_items)\n",
    "                while (user, j) in self.train_matrix or j == item:\n",
    "                    j = np.random.randint(1, self.n_items)\n",
    "                negatives.append(j)\n",
    "            negativeList.append(negatives)\n",
    "        return negativeList\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network with 3 hidden layers and input as concated embeddings for users and items. It return the probability of \n",
    "# that user will watch the given item\n",
    "class recommendationNetwork(nn.Module):\n",
    "    def __init__(self, n_users, n_items,embedding_dim):\n",
    "        super().__init__()\n",
    "        self.user_embed = torch.nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embed = torch.nn.Embedding(n_items, embedding_dim)\n",
    "        self.linear1 = nn.Linear(2*embedding_dim,32)\n",
    "        self.linear2 = nn.Linear(32,16)\n",
    "        self.linear3 = nn.Linear(16,8)\n",
    "        self.output = nn.Linear(8,1)\n",
    "#         self.D = torch.nn.Dropout(0.1)\n",
    "        \n",
    "    \n",
    "    def forward(self, inputUserItem):\n",
    "        users = inputUserItem['user_id']\n",
    "        items = inputUserItem['item_id']\n",
    "        user_embedding = self.user_embed(users)\n",
    "        item_embedding = self.item_embed(items)\n",
    "        # concatenate user and item embeddings to form input\n",
    "        input_embedding = torch.cat([user_embedding, item_embedding], 1)\n",
    "        hidden1 = (F.relu(self.linear1(input_embedding)))\n",
    "        hidden2 = (F.relu(self.linear2(hidden1)))\n",
    "        hidden3 = (F.relu(self.linear3(hidden2)))\n",
    "        output = torch.sigmoid(self.output(hidden3))\n",
    "        return output\n",
    "\n",
    "    def predict(self, inputUserItem):\n",
    "        # return the score, inputs and outputs are numpy arrays\n",
    "        for key in inputUserItem:\n",
    "            if type(inputUserItem[key])!= type(None):\n",
    "                inputUserItem[key] = torch.from_numpy(inputUserItem[key]).to(dtype=torch.long, device=device)\n",
    "        output_scores = self.forward(inputUserItem)\n",
    "        return output_scores.cpu().detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "# function to evaluate the performance of trained model on complete test dataset using the metric of hit-ratio. \n",
    "\n",
    "def evaluate_model(model,testRatings,testNegatives,topK: int):\n",
    "    hitratio = []\n",
    "    for idx in range(len(testRatings)):\n",
    "    \n",
    "        itemsList = testNegatives[idx]\n",
    "        u = testRatings[idx][0]\n",
    "        positiveItem = testRatings[idx][1]\n",
    "        itemsList.append(positiveItem)\n",
    "        map_item_score = {}\n",
    "        users = np.full(len(itemsList), u, dtype='int32')\n",
    "\n",
    "        data = {\n",
    "            'user_id': users,\n",
    "            'item_id': np.array(itemsList),\n",
    "        }\n",
    "        predictions = model.predict(data)\n",
    "        for i in range(len(itemsList)):\n",
    "            item = itemsList[i]\n",
    "            map_item_score[item] = predictions[i]\n",
    "        ranklist = heapq.nlargest(topK, map_item_score, key=map_item_score.get)\n",
    "        hr = getHitRatio(ranklist, positiveItem)\n",
    "        hitratio.append(hr)\n",
    "    return hitratio\n",
    "\n",
    "def getHitRatio(ranklist, positiveItem):\n",
    "    for item in ranklist:\n",
    "        if item == positiveItem:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset from local and creating movielensdataset class to generate a spare train matrix and test datastet\n",
    "dataset = MovieLensDataset(\"/Users/shiprajain/Desktop/RecommenderSystem/movielens/movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch's dataloader shuffles the datapoints and divide it in batches of fixed size for batch training \n",
    "training_data_generator = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.train_matrix\n",
    "num_users, num_items = train.shape\n",
    "model = recommendationNetwork(num_users, num_items,8)\n",
    "model.to(device)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0\n",
      "average loss :  0.39431801856744914\n",
      "average hit ratio :  0.39660657476139977\n",
      "epoch :  1\n",
      "average loss :  0.32912987462925974\n",
      "average hit ratio :  0.4061505832449629\n",
      "epoch :  2\n",
      "average loss :  0.322510433796405\n",
      "average hit ratio :  0.41145281018027574\n",
      "epoch :  3\n",
      "average loss :  0.3191268353640366\n",
      "average hit ratio :  0.40721102863202546\n",
      "epoch :  4\n",
      "average loss :  0.3166667561236894\n",
      "average hit ratio :  0.40827147401908803\n",
      "epoch :  5\n",
      "average loss :  0.3137715369219106\n",
      "average hit ratio :  0.4252386002120891\n",
      "epoch :  6\n",
      "average loss :  0.30879563881881683\n",
      "average hit ratio :  0.45387062566277836\n",
      "epoch :  7\n",
      "average loss :  0.30085556898955945\n",
      "average hit ratio :  0.47932131495228\n",
      "epoch :  8\n",
      "average loss :  0.29245117974758766\n",
      "average hit ratio :  0.5058324496288441\n",
      "epoch :  9\n",
      "average loss :  0.2856951417797706\n",
      "average hit ratio :  0.5185577942735949\n",
      "epoch :  10\n",
      "average loss :  0.28030305889071727\n",
      "average hit ratio :  0.5323435843054083\n",
      "epoch :  11\n",
      "average loss :  0.2758272776731533\n",
      "average hit ratio :  0.5440084835630965\n",
      "epoch :  12\n",
      "average loss :  0.2720946815766516\n",
      "average hit ratio :  0.5535524920466596\n",
      "epoch :  13\n",
      "average loss :  0.2688763431120186\n",
      "average hit ratio :  0.542948038176034\n",
      "epoch :  14\n",
      "average loss :  0.2662139891435831\n",
      "average hit ratio :  0.5620360551431601\n",
      "epoch :  15\n",
      "average loss :  0.26411449113454827\n",
      "average hit ratio :  0.5535524920466596\n",
      "epoch :  16\n",
      "average loss :  0.2622653011819805\n",
      "average hit ratio :  0.5524920466595971\n",
      "epoch :  17\n",
      "average loss :  0.26049521547468646\n",
      "average hit ratio :  0.5556733828207847\n",
      "epoch :  18\n",
      "average loss :  0.258936394150405\n",
      "average hit ratio :  0.5503711558854719\n",
      "epoch :  19\n",
      "average loss :  0.25738462090209885\n",
      "average hit ratio :  0.5630965005302226\n",
      "epoch :  20\n",
      "average loss :  0.2562505930187269\n",
      "average hit ratio :  0.5652173913043478\n",
      "epoch :  21\n",
      "average loss :  0.25503036011456415\n",
      "average hit ratio :  0.5726405090137858\n",
      "epoch :  22\n",
      "average loss :  0.2538635620107741\n",
      "average hit ratio :  0.5620360551431601\n",
      "epoch :  23\n",
      "average loss :  0.2528267880319317\n",
      "average hit ratio :  0.5683987274655355\n",
      "epoch :  24\n",
      "average loss :  0.25196717114770956\n",
      "average hit ratio :  0.5705196182396607\n",
      "epoch :  25\n",
      "average loss :  0.2508413978659008\n",
      "average hit ratio :  0.5821845174973489\n",
      "epoch :  26\n",
      "average loss :  0.2500955843070681\n",
      "average hit ratio :  0.5874867444326617\n",
      "epoch :  27\n",
      "average loss :  0.24925959513913343\n",
      "average hit ratio :  0.5864262990455992\n",
      "epoch :  28\n",
      "average loss :  0.24863296297349158\n",
      "average hit ratio :  0.5779427359490986\n",
      "epoch :  29\n",
      "average loss :  0.24773119894417064\n",
      "average hit ratio :  0.5726405090137858\n",
      "epoch :  30\n",
      "average loss :  0.24713069928246875\n",
      "average hit ratio :  0.5790031813361611\n",
      "epoch :  31\n",
      "average loss :  0.24644476408900937\n",
      "average hit ratio :  0.5790031813361611\n",
      "epoch :  32\n",
      "average loss :  0.24576746862988139\n",
      "average hit ratio :  0.5874867444326617\n",
      "epoch :  33\n",
      "average loss :  0.24521868347698095\n",
      "average hit ratio :  0.5758218451749735\n",
      "epoch :  34\n",
      "average loss :  0.2445299737700915\n",
      "average hit ratio :  0.5811240721102863\n",
      "epoch :  35\n",
      "average loss :  0.24414169977673367\n",
      "average hit ratio :  0.5683987274655355\n",
      "epoch :  36\n",
      "average loss :  0.24337288005715502\n",
      "average hit ratio :  0.5652173913043478\n",
      "epoch :  37\n",
      "average loss :  0.2429934286421789\n",
      "average hit ratio :  0.5726405090137858\n",
      "epoch :  38\n",
      "average loss :  0.24219658873930355\n",
      "average hit ratio :  0.5800636267232238\n",
      "epoch :  39\n",
      "average loss :  0.24170203331110296\n",
      "average hit ratio :  0.5811240721102863\n",
      "epoch :  40\n",
      "average loss :  0.2414726677393215\n",
      "average hit ratio :  0.584305408271474\n",
      "epoch :  41\n",
      "average loss :  0.24092584542294807\n",
      "average hit ratio :  0.5779427359490986\n",
      "epoch :  42\n",
      "average loss :  0.24039833881057202\n",
      "average hit ratio :  0.5885471898197243\n",
      "epoch :  43\n",
      "average loss :  0.2400274467778863\n",
      "average hit ratio :  0.5864262990455992\n",
      "epoch :  44\n",
      "average loss :  0.23960654217425756\n",
      "average hit ratio :  0.5768822905620361\n",
      "epoch :  45\n",
      "average loss :  0.23918780149261465\n",
      "average hit ratio :  0.5790031813361611\n",
      "epoch :  46\n",
      "average loss :  0.23883683122790753\n",
      "average hit ratio :  0.5811240721102863\n",
      "epoch :  47\n",
      "average loss :  0.2384467310337133\n",
      "average hit ratio :  0.5737009544008483\n",
      "epoch :  48\n",
      "average loss :  0.23791339471101966\n",
      "average hit ratio :  0.5726405090137858\n",
      "epoch :  49\n",
      "average loss :  0.23757247860374173\n",
      "average hit ratio :  0.584305408271474\n"
     ]
    }
   ],
   "source": [
    "# training the model with adam optimizer and binary cross entropy loss function and testing its performance for every epoch\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for data in training_data_generator:\n",
    "        for key in data:\n",
    "            if type(data[key]) != type(None):\n",
    "                data[key] = data[key].to(dtype = torch.long, device = device)\n",
    "        prediction = model(data)\n",
    "        rating = data['rating']\n",
    "        rating = rating.float().view(prediction.size())  \n",
    "        loss = loss_fn(prediction, rating)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    hitRatios = evaluate_model(model,dataset.testRatings,dataset.testNegatives,10)\n",
    "    print(\"epoch : \", epoch)\n",
    "    print(\"average loss : \",np.mean(epoch_loss))\n",
    "    print(\"average hit ratio : \",np.mean(hitRatios))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
